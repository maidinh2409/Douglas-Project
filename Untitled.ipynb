{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c133ffb9-0f9f-42fb-9949-7649fc0f7b45",
   "metadata": {},
   "source": [
    "# Pop (1) vs. Rock (0) Lyrics Classification (NLP + ML)\n",
    "\n",
    "## Objective\n",
    "Build a binary text-classification model in Python to predict music genre using lyrics:\n",
    "- **Pop = 1**\n",
    "- **Rock = 0**\n",
    "\n",
    "---\n",
    "\n",
    "## 1) Dataset Loading\n",
    "\n",
    "### Steps\n",
    "1. Load the provided dataset (lyrics + label).\n",
    "2. Split the dataset into:\n",
    "   - **Training set: 70%**\n",
    "   - **Test set: 30%**\n",
    "\n",
    "---\n",
    "\n",
    "## 2) Data Pre-processing\n",
    "\n",
    "### Steps\n",
    "Apply the following preprocessing to the text:\n",
    "\n",
    "- Convert text to **lowercase**\n",
    "- **Tokenize** the text (split into tokens/words)\n",
    "- Remove:\n",
    "  - **stopwords**\n",
    "  - **punctuation**\n",
    "- Apply **lemmatization** (or stemming)\n",
    "\n",
    "> **Important:** Fit/define preprocessing on the training pipeline and apply the same transformation to the test set (do not “learn” from test labels).\n",
    "\n",
    "---\n",
    "\n",
    "## 3) Feature Engineering\n",
    "\n",
    "Convert processed text into numerical vectors using **one** (or compare both):\n",
    "\n",
    "### Option A — Bag of Words (BoW)\n",
    "- Represents text as word counts\n",
    "- Common baseline for text classification\n",
    "\n",
    "### Option B — TF-IDF\n",
    "- Weights words by importance across documents\n",
    "- Often improves results vs raw counts for classification\n",
    "\n",
    "---\n",
    "\n",
    "## 4) Model Training\n",
    "\n",
    "Train **all three** binary classifiers:\n",
    "\n",
    "1. **Logistic Regression**\n",
    "2. **Linear Support Vector Machine (SVM)**\n",
    "3. **Naive Bayes**\n",
    "\n",
    "---\n",
    "\n",
    "## 5) Model Evaluation\n",
    "\n",
    "Evaluate performance on the **test set** using:\n",
    "\n",
    "- **Precision**\n",
    "- **Recall**\n",
    "- **F1-score**\n",
    "\n",
    "Output using:\n",
    "- `classification_report`\n",
    "\n",
    "---\n",
    "\n",
    "## 6) Conclusions\n",
    "\n",
    "Write conclusions based on observed results, such as:\n",
    "\n",
    "- Which model performs best overall (macro/weighted F1)?\n",
    "- Which model balances precision vs recall better?\n",
    "- Does TF-IDF outperform BoW (or vice versa)?\n",
    "- Any common error patterns (e.g., misclassified songs with ambiguous lyrics)?\n",
    "\n",
    "---\n",
    "\n",
    "## Deliverables Checklist ✅\n",
    "- [ ] Dataset loaded correctly  \n",
    "- [ ] 70/30 split completed  \n",
    "- [ ] Preprocessing applied (lowercase, tokenize, stopwords, punctuation, lemma/stem)  \n",
    "- [ ] Feature extraction (BoW and/or TF-IDF)  \n",
    "- [ ] Trained 3 models (LR, Linear SVM, Naive Bayes)  \n",
    "- [ ] Printed classification report for each model  \n",
    "- [ ] Written conclusions based on metrics and comparisons  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87208755-f421-463e-beda-b41cec07f8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\300312139\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\300312139\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\300312139\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaee1c6e-0bb4-44ab-90b8-c87995e65681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Another one bites the dust, and another's gone.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We will, we yeah rock you, pounding our feet o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm on the highway to hell, and I'm you know d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sweet child o' mine, umm got eyes of the blues...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oh keep dancing on my own, but now you're gone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>I'm on you know of the world, waiting for you ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>uhh will, we will rock you, pounding our feet ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>Just baby a dream, the best thing in my life.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>Knockin' on heaven's door, can't take this any...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>Another one bites the dust, and another's gone.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0       Another one bites the dust, and another's gone.      0\n",
       "1     We will, we yeah rock you, pounding our feet o...      0\n",
       "2     I'm on the highway to hell, and I'm you know d...      0\n",
       "3     Sweet child o' mine, umm got eyes of the blues...      0\n",
       "4       oh keep dancing on my own, but now you're gone.      1\n",
       "...                                                 ...    ...\n",
       "1995  I'm on you know of the world, waiting for you ...      1\n",
       "1996  uhh will, we will rock you, pounding our feet ...      0\n",
       "1997      Just baby a dream, the best thing in my life.      1\n",
       "1998  Knockin' on heaven's door, can't take this any...      0\n",
       "1999    Another one bites the dust, and another's gone.      0\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"pop_vs_rock_lyrics_classification.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24ec4732-d62c-4988-96d5-db7337bb1f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text']\n",
    "y = df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.33333, random_state = 42, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3631ffa0-97f2-4760-839b-43ce40007100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1677    you're beautiful, it's true, i can't take my o...\n",
       "329     we found love in a hopeless place, bright and uhh\n",
       "6       you're beautiful, it's true, i can't take baby...\n",
       "745     knockin' on heaven's door, can't take this any...\n",
       "1553    you're the one that i want, can't get you out ...\n",
       "                              ...                        \n",
       "1130       don't stop believin', hold on to that feeling.\n",
       "1294    baby, umm a song, you make me wanna roll my wi...\n",
       "860     baby, oh a song, you make me wanna roll my win...\n",
       "1459    you're the one baby i want, can't get you out ...\n",
       "1126         welcome to the jungle, we got fun and games.\n",
       "Name: text, Length: 1333, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.str.lower()\n",
    "X_test = X_test.str.lower()\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8711136c-ba18-4deb-a1f8-56cdf6328e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1677    [you, re, beautiful, it, s, true, i, can, t, t...\n",
       "329     [we, found, love, in, a, hopeless, place, brig...\n",
       "6       [you, re, beautiful, it, s, true, i, can, t, t...\n",
       "745     [knockin, on, heaven, s, door, can, t, take, t...\n",
       "1553    [you, re, the, one, that, i, want, can, t, get...\n",
       "                              ...                        \n",
       "1130    [don, t, stop, believin, hold, on, to, that, f...\n",
       "1294    [baby, umm, a, song, you, make, me, wanna, rol...\n",
       "860     [baby, oh, a, song, you, make, me, wanna, roll...\n",
       "1459    [you, re, the, one, baby, i, want, can, t, get...\n",
       "1126    [welcome, to, the, jungle, we, got, fun, and, ...\n",
       "Name: text, Length: 1333, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_words(x):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    return tokenizer.tokenize(x)\n",
    "\n",
    "X_train = X_train.apply(tokenize_words)\n",
    "X_test = X_test.apply(tokenize_words)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10a99b25-1d7f-444f-88fa-da2c6c268fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(stopwords.words('english'))\n",
    "stopwords\n",
    "\n",
    "def remove_stopwords(x):\n",
    "    return [word for word in x if word not in stopwords]\n",
    "\n",
    "X_train = X_train.apply(remove_stopwords)\n",
    "X_test = X_test.apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e45e0e42-1584-4a3b-8ab3-bf72c49a450d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1677                      [beautiful, true, take, oh]\n",
       "329       [found, love, hopeless, place, bright, uhh]\n",
       "6                 [beautiful, true, take, baby, eyes]\n",
       "745            [knockin, heaven, door, take, anymore]\n",
       "1553                      [one, want, get, uhh, head]\n",
       "                            ...                      \n",
       "1130                  [stop, believin, hold, feeling]\n",
       "1294    [baby, umm, song, make, wanna, roll, windows]\n",
       "860      [baby, oh, song, make, wanna, roll, windows]\n",
       "1459                     [one, baby, want, get, head]\n",
       "1126               [welcome, jungle, got, fun, games]\n",
       "Name: text, Length: 1333, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc5d0ebf-3d89-4c65-8c66-c72ed77fb74a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1677                     [beautiful, true, take, oh]\n",
       "329      [found, love, hopeless, place, bright, uhh]\n",
       "6                 [beautiful, true, take, baby, eye]\n",
       "745           [knockin, heaven, door, take, anymore]\n",
       "1553                     [one, want, get, uhh, head]\n",
       "                            ...                     \n",
       "1130                 [stop, believin, hold, feeling]\n",
       "1294    [baby, umm, song, make, wanna, roll, window]\n",
       "860      [baby, oh, song, make, wanna, roll, window]\n",
       "1459                    [one, baby, want, get, head]\n",
       "1126               [welcome, jungle, got, fun, game]\n",
       "Name: text, Length: 1333, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lemmatize_tokens(x):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(word) for word in x]\n",
    "\n",
    "X_train = X_train.apply(lemmatize_tokens)\n",
    "X_test = X_test.apply(lemmatize_tokens)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "595508eb-b696-42df-9626-6729632b2fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1860      [another, one, bite, dust, another, gone]\n",
       "353       [another, one, bite, dust, another, gone]\n",
       "1333                            [yeah, hell, going]\n",
       "905          [knockin, heaven, door, take, anymore]\n",
       "1289            [get, satisfaction, yeah, try, try]\n",
       "                           ...                     \n",
       "1018    [sweet, child, yeah, got, eye, bluest, sky]\n",
       "380             [uhh, rock, pounding, foot, ground]\n",
       "1029        [want, know, moment, feel, light, love]\n",
       "1688           [baby, rock, pounding, foot, ground]\n",
       "84                      [highway, umm, hell, going]\n",
       "Name: text, Length: 667, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8ee89f5-ba8f-4843-b211-d0a0fec2b833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_text(x):\n",
    "    return ' '.join(x)\n",
    "\n",
    "X_train = X_train.apply(join_text)\n",
    "X_test = X_test.apply(join_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8558699-6a34-4332-9a4c-ffc8d8ed0c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 1, ..., 1, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_vectorizer = CountVectorizer(\n",
    "    analyzer = 'word',\n",
    "    ngram_range=(1,1)\n",
    ")\n",
    "\n",
    "X_train_bow = bow_vectorizer.fit_transform(X_train)\n",
    "X_test_bow = bow_vectorizer.transform(X_test)\n",
    "X_train_bow.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2ec38f7-0818-4d15-9608-19959a4e310a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['another', 'anymore', 'baby', 'beautiful', 'believin', 'best',\n",
       "       'bite', 'bluest', 'bright', 'burst', 'call', 'child', 'color',\n",
       "       'come', 'dancing', 'denial', 'door', 'dream', 'dust', 'eye',\n",
       "       'feel', 'feeling', 'firework', 'foot', 'forever', 'found', 'fun',\n",
       "       'game', 'get', 'going', 'gone', 'gonna', 'got', 'ground', 'head',\n",
       "       'heaven', 'hell', 'highway', 'hold', 'hopeless', 'jungle', 'keep',\n",
       "       'knockin', 'know', 'let', 'life', 'light', 'like', 'live', 'love',\n",
       "       'make', 'mine', 'moment', 'never', 'oh', 'one', 'place',\n",
       "       'pounding', 'rock', 'roll', 'satisfaction', 'sky', 'smell', 'song',\n",
       "       'spirit', 'stop', 'sweet', 'take', 'talk', 'teen', 'thing', 'top',\n",
       "       'true', 'try', 'uhh', 'umm', 'used', 'waiting', 'wanna', 'want',\n",
       "       'welcome', 'window', 'world', 'yeah'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ee734d6-6feb-4f8e-ba81-e0289d4a6f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.37857506, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.29119678, ..., 0.40535325, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.38187003, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "X_train_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a18b3e31-8dc8-4678-abc0-f6191ce55e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['another', 'anymore', 'baby', 'beautiful', 'believin', 'best',\n",
       "       'bite', 'bluest', 'bright', 'burst', 'call', 'child', 'color',\n",
       "       'come', 'dancing', 'denial', 'door', 'dream', 'dust', 'eye',\n",
       "       'feel', 'feeling', 'firework', 'foot', 'forever', 'found', 'fun',\n",
       "       'game', 'get', 'going', 'gone', 'gonna', 'got', 'ground', 'head',\n",
       "       'heaven', 'hell', 'highway', 'hold', 'hopeless', 'jungle', 'keep',\n",
       "       'knockin', 'know', 'let', 'life', 'light', 'like', 'live', 'love',\n",
       "       'make', 'mine', 'moment', 'never', 'oh', 'one', 'place',\n",
       "       'pounding', 'rock', 'roll', 'satisfaction', 'sky', 'smell', 'song',\n",
       "       'spirit', 'stop', 'sweet', 'take', 'talk', 'teen', 'thing', 'top',\n",
       "       'true', 'try', 'uhh', 'umm', 'used', 'waiting', 'wanna', 'want',\n",
       "       'welcome', 'window', 'world', 'yeah'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41eec3b5-ed18-4a49-a3cc-571f28ad2108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most rare word in documents\n",
      "top : 4.324736215567678\n",
      "waiting : 4.283914221047423\n",
      "world : 4.2641115937512435\n",
      "call : 4.225645312923447\n",
      "going : 4.225645312923447\n",
      "true : 4.188604041243098\n",
      "forever : 4.17058553574042\n",
      "live : 4.17058553574042\n",
      "keep : 4.1528859586410185\n",
      "satisfaction : 4.1528859586410185\n",
      "thing : 4.13549421592915\n",
      "wanna : 4.13549421592915\n",
      "foot : 4.118399782569849\n",
      "best : 4.101592664253468\n",
      "dancing : 4.101592664253468\n",
      "denial : 4.101592664253468\n",
      "dream : 4.101592664253468\n",
      "hell : 4.101592664253468\n",
      "highway : 4.101592664253468\n",
      "never : 4.101592664253468\n",
      "pounding : 4.101592664253468\n",
      "rock : 4.101592664253468\n",
      "smell : 4.101592664253468\n",
      "spirit : 4.101592664253468\n",
      "teen : 4.101592664253468\n",
      "place : 4.085063362302257\n",
      "bright : 4.068802841430477\n",
      "ground : 4.068802841430477\n",
      "make : 4.068802841430477\n",
      "window : 4.068802841430477\n",
      "found : 4.052802500084036\n",
      "gonna : 4.052802500084036\n",
      "head : 4.052802500084036\n",
      "roll : 4.052802500084036\n",
      "hopeless : 4.021549956579932\n",
      "moment : 4.021549956579932\n",
      "song : 4.021549956579932\n",
      "try : 4.021549956579932\n",
      "fun : 4.006282484449144\n",
      "game : 4.006282484449144\n",
      "jungle : 4.006282484449144\n",
      "welcome : 4.006282484449144\n",
      "sweet : 3.991244607084603\n",
      "talk : 3.991244607084603\n",
      "used : 3.991244607084603\n",
      "light : 3.9764295212994623\n",
      "mine : 3.9764295212994623\n",
      "sky : 3.9764295212994623\n",
      "bluest : 3.9618307218783095\n",
      "child : 3.9332573494342538\n",
      "another : 3.919271107459514\n",
      "bite : 3.919271107459514\n",
      "dust : 3.919271107459514\n",
      "believin : 3.905477785327178\n",
      "door : 3.905477785327178\n",
      "feeling : 3.905477785327178\n",
      "heaven : 3.905477785327178\n",
      "hold : 3.905477785327178\n",
      "knockin : 3.905477785327178\n",
      "stop : 3.905477785327178\n",
      "feel : 3.8918721332713995\n",
      "burst : 3.865203886189238\n",
      "color : 3.865203886189238\n",
      "come : 3.865203886189238\n",
      "firework : 3.865203886189238\n",
      "let : 3.865203886189238\n",
      "life : 3.433763291677813\n",
      "beautiful : 3.408445483693523\n",
      "get : 3.3837528711031517\n",
      "gone : 3.3837528711031517\n",
      "want : 3.367623489173268\n",
      "yeah : 3.367623489173268\n",
      "eye : 3.3284027760199866\n",
      "love : 3.305588098253815\n",
      "got : 3.2980974265246576\n",
      "one : 3.2906624480371396\n",
      "take : 3.2906624480371396\n",
      "know : 3.275956300647444\n",
      "umm : 3.275956300647444\n",
      "anymore : 3.2614632933448773\n",
      "uhh : 3.2192034840549946\n",
      "oh : 3.0660385115524957\n",
      "like : 2.970190552762368\n",
      "baby : 2.922937667911822\n"
     ]
    }
   ],
   "source": [
    "tfidf_list = dict(zip (tfidf_vectorizer.get_feature_names_out(), tfidf_vectorizer.idf_))\n",
    "\n",
    "def get_idf_values(x):\n",
    "    return x[1]\n",
    "\n",
    "tfidf_sorted = sorted(tfidf_list.items() , key=get_idf_values, reverse = True)\n",
    "print(\"Most rare word in documents\")\n",
    "for el1, el2 in tfidf_sorted:\n",
    "    print(el1, \":\", el2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2097047-93de-4946-adf0-b813ec43037d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1.0\n",
      "Test: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       332\n",
      "           1       1.00      1.00      1.00       335\n",
      "\n",
      "    accuracy                           1.00       667\n",
      "   macro avg       1.00      1.00      1.00       667\n",
      "weighted avg       1.00      1.00      1.00       667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logModel = LogisticRegression(max_iter=10000, random_state=0)\n",
    "\n",
    "logModel.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred = logModel.predict(X_test_tfidf)\n",
    "train_acc = accuracy_score(y_train, logModel.predict(X_train_tfidf))\n",
    "test_acc  = accuracy_score(y_test, logModel.predict(X_test_tfidf))\n",
    "\n",
    "print(\"Train:\", train_acc)\n",
    "print(\"Test:\", test_acc)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d90bfcd-0136-4b25-951a-be60f2c9b075",
   "metadata": {},
   "outputs": [],
   "source": [
    "logModel2 = LogisticRegression(max_iter=10000, random_state=0)\n",
    "\n",
    "logModel2.fit(X_train_bow, y_train)\n",
    "\n",
    "y_pred = logModel.predict(X_)\n",
    "train_acc = accuracy_score(y_train, logModel.predict(X_train_tfidf))\n",
    "test_acc  = accuracy_score(y_test, logModel.predict(X_test_tfidf))\n",
    "\n",
    "print(\"Train:\", train_acc)\n",
    "print(\"Test:\", test_acc)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5366ed4c-9d03-46e5-8ea5-7aa33a85f21f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Train: 1.0\n",
      "SVM Test: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       332\n",
      "           1       1.00      1.00      1.00       335\n",
      "\n",
      "    accuracy                           1.00       667\n",
      "   macro avg       1.00      1.00      1.00       667\n",
      "weighted avg       1.00      1.00      1.00       667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Khởi tạo model\n",
    "svmModel = LinearSVC(random_state=0)\n",
    "\n",
    "# Train\n",
    "svmModel.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_svm = svmModel.predict(X_test_tfidf)\n",
    "\n",
    "# Accuracy\n",
    "train_acc_svm = accuracy_score(y_train, svmModel.predict(X_train_tfidf))\n",
    "test_acc_svm  = accuracy_score(y_test, y_pred_svm)\n",
    "\n",
    "print(\"SVM Train:\", train_acc_svm)\n",
    "print(\"SVM Test:\", test_acc_svm)\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2da19a1c-f32a-4d83-84e5-5b2945e68341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 3281 stored elements and shape (667, 84)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98494b19-9b0c-4733-ba63-de6ce290e51b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1860     another one bite dust another gone\n",
       "353      another one bite dust another gone\n",
       "1333                        yeah hell going\n",
       "905        knockin heaven door take anymore\n",
       "1289          get satisfaction yeah try try\n",
       "                       ...                 \n",
       "1018    sweet child yeah got eye bluest sky\n",
       "380           uhh rock pounding foot ground\n",
       "1029       want know moment feel light love\n",
       "1688         baby rock pounding foot ground\n",
       "84                   highway umm hell going\n",
       "Name: text, Length: 667, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01f7a9c5-e959-42eb-9a81-fad379aff861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1677                  beautiful true take oh\n",
       "329     found love hopeless place bright uhh\n",
       "6               beautiful true take baby eye\n",
       "745         knockin heaven door take anymore\n",
       "1553                   one want get uhh head\n",
       "                        ...                 \n",
       "1130              stop believin hold feeling\n",
       "1294    baby umm song make wanna roll window\n",
       "860      baby oh song make wanna roll window\n",
       "1459                  one baby want get head\n",
       "1126             welcome jungle got fun game\n",
       "Name: text, Length: 1333, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bb125e-7d64-40b3-b163-c057b2a3c2b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
